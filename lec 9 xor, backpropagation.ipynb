{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.72739744\n",
      "100 0.69518095\n",
      "200 0.6938137\n",
      "300 0.6933774\n",
      "400 0.6932311\n",
      "500 0.6931795\n",
      "600 0.6931602\n",
      "700 0.6931526\n",
      "800 0.6931495\n",
      "900 0.6931482\n",
      "1000 0.6931476\n",
      "1100 0.6931474\n",
      "1200 0.6931473\n",
      "1300 0.69314724\n",
      "1400 0.6931472\n",
      "1500 0.6931472\n",
      "1600 0.6931472\n",
      "1700 0.6931472\n",
      "1800 0.6931472\n",
      "1900 0.6931471\n",
      "2000 0.6931472\n",
      "2100 0.6931472\n",
      "2200 0.6931472\n",
      "2300 0.6931472\n",
      "2400 0.6931472\n",
      "2500 0.6931472\n",
      "2600 0.6931472\n",
      "2700 0.6931472\n",
      "2800 0.6931472\n",
      "2900 0.6931472\n",
      "3000 0.6931472\n",
      "3100 0.69314724\n",
      "3200 0.6931472\n",
      "3300 0.6931472\n",
      "3400 0.6931472\n",
      "3500 0.6931472\n",
      "3600 0.6931472\n",
      "3700 0.6931472\n",
      "3800 0.6931472\n",
      "3900 0.6931472\n",
      "4000 0.6931472\n",
      "4100 0.6931472\n",
      "4200 0.6931472\n",
      "4300 0.6931472\n",
      "4400 0.6931472\n",
      "4500 0.6931472\n",
      "4600 0.6931472\n",
      "4700 0.6931472\n",
      "4800 0.6931472\n",
      "4900 0.6931472\n",
      "5000 0.6931472\n",
      "5100 0.6931472\n",
      "5200 0.6931472\n",
      "5300 0.6931472\n",
      "5400 0.6931472\n",
      "5500 0.6931472\n",
      "5600 0.6931472\n",
      "5700 0.6931472\n",
      "5800 0.6931472\n",
      "5900 0.6931472\n",
      "6000 0.6931472\n",
      "6100 0.6931472\n",
      "6200 0.6931472\n",
      "6300 0.6931472\n",
      "6400 0.6931472\n",
      "6500 0.6931472\n",
      "6600 0.6931472\n",
      "6700 0.6931472\n",
      "6800 0.6931472\n",
      "6900 0.6931472\n",
      "7000 0.6931472\n",
      "7100 0.6931472\n",
      "7200 0.6931472\n",
      "7300 0.6931472\n",
      "7400 0.6931472\n",
      "7500 0.6931472\n",
      "7600 0.6931472\n",
      "7700 0.6931472\n",
      "7800 0.6931472\n",
      "7900 0.6931472\n",
      "8000 0.6931472\n",
      "8100 0.6931472\n",
      "8200 0.6931472\n",
      "8300 0.6931472\n",
      "8400 0.6931472\n",
      "8500 0.6931472\n",
      "8600 0.6931472\n",
      "8700 0.6931472\n",
      "8800 0.6931472\n",
      "8900 0.6931472\n",
      "9000 0.6931472\n",
      "9100 0.6931472\n",
      "9200 0.6931472\n",
      "9300 0.6931472\n",
      "9400 0.6931472\n",
      "9500 0.6931472\n",
      "9600 0.6931472\n",
      "9700 0.6931472\n",
      "9800 0.6931472\n",
      "9900 0.6931472\n",
      "10000 0.6931472\n",
      "\n",
      "Hypothesis:  [[0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]] \n",
      "Correct:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]] \n",
      "Accuracy:  tensor(0.5000)\n"
     ]
    }
   ],
   "source": [
    "# NN for XOR\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(777)  # for reproducibility\n",
    "\n",
    "x_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.float32)\n",
    "y_data = np.array([[0], [1], [1], [0]], dtype=np.float32)\n",
    "\n",
    "X = Variable(torch.from_numpy(x_data))\n",
    "Y = Variable(torch.from_numpy(y_data))\n",
    "\n",
    "# Hypothesis using sigmoid\n",
    "linear = torch.nn.Linear(2, 1, bias=True)\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "model = torch.nn.Sequential(linear, sigmoid)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "for step in range(10001):\n",
    "    optimizer.zero_grad()\n",
    "    hypothesis = model(X)\n",
    "    \n",
    "    # cost/loss function\n",
    "    cost = -(Y * torch.log(hypothesis) + (1 - Y)\n",
    "             * torch.log(1 - hypothesis)).mean()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if step % 100 == 0:\n",
    "        print(step, cost.data.numpy())\n",
    "\n",
    "# Accuracy computation\n",
    "# True if hypothesis>0.5 else False\n",
    "predicted = (model(X).data > 0.5).float()\n",
    "accuracy = (predicted == Y.data).float().mean()\n",
    "print(\"\\nHypothesis: \", hypothesis.data.numpy(), \"\\nCorrect: \", predicted.numpy(), \"\\nAccuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7434073\n",
      "100 0.69318384\n",
      "200 0.69317234\n",
      "300 0.69317126\n",
      "400 0.69317025\n",
      "500 0.69316936\n",
      "600 0.6931684\n",
      "700 0.6931675\n",
      "800 0.6931666\n",
      "900 0.6931658\n",
      "1000 0.69316494\n",
      "1100 0.6931641\n",
      "1200 0.6931633\n",
      "1300 0.6931625\n",
      "1400 0.6931617\n",
      "1500 0.693161\n",
      "1600 0.6931603\n",
      "1700 0.69315964\n",
      "1800 0.69315886\n",
      "1900 0.6931582\n",
      "2000 0.69315755\n",
      "2100 0.6931569\n",
      "2200 0.69315624\n",
      "2300 0.69315565\n",
      "2400 0.69315493\n",
      "2500 0.69315434\n",
      "2600 0.6931538\n",
      "2700 0.6931532\n",
      "2800 0.6931526\n",
      "2900 0.693152\n",
      "3000 0.6931514\n",
      "3100 0.6931508\n",
      "3200 0.69315034\n",
      "3300 0.69314975\n",
      "3400 0.69314915\n",
      "3500 0.6931487\n",
      "3600 0.69314814\n",
      "3700 0.69314766\n",
      "3800 0.69314706\n",
      "3900 0.6931465\n",
      "4000 0.693146\n",
      "4100 0.6931454\n",
      "4200 0.6931449\n",
      "4300 0.69314444\n",
      "4400 0.69314384\n",
      "4500 0.69314325\n",
      "4600 0.6931428\n",
      "4700 0.6931423\n",
      "4800 0.6931418\n",
      "4900 0.6931413\n",
      "5000 0.69314075\n",
      "5100 0.69314015\n",
      "5200 0.69313955\n",
      "5300 0.693139\n",
      "5400 0.6931385\n",
      "5500 0.693138\n",
      "5600 0.69313735\n",
      "5700 0.6931369\n",
      "5800 0.6931362\n",
      "5900 0.69313574\n",
      "6000 0.69313514\n",
      "6100 0.69313455\n",
      "6200 0.69313395\n",
      "6300 0.69313335\n",
      "6400 0.69313276\n",
      "6500 0.69313216\n",
      "6600 0.69313145\n",
      "6700 0.69313085\n",
      "6800 0.69313014\n",
      "6900 0.69312954\n",
      "7000 0.6931288\n",
      "7100 0.6931281\n",
      "7200 0.6931274\n",
      "7300 0.6931267\n",
      "7400 0.69312596\n",
      "7500 0.69312525\n",
      "7600 0.6931245\n",
      "7700 0.6931237\n",
      "7800 0.69312286\n",
      "7900 0.693122\n",
      "8000 0.69312114\n",
      "8100 0.69312036\n",
      "8200 0.6931194\n",
      "8300 0.69311845\n",
      "8400 0.6931176\n",
      "8500 0.69311666\n",
      "8600 0.6931156\n",
      "8700 0.6931147\n",
      "8800 0.69311357\n",
      "8900 0.6931125\n",
      "9000 0.69311136\n",
      "9100 0.6931102\n",
      "9200 0.69310915\n",
      "9300 0.69310784\n",
      "9400 0.69310665\n",
      "9500 0.6931053\n",
      "9600 0.69310397\n",
      "9700 0.6931026\n",
      "9800 0.69310117\n",
      "9900 0.69309974\n",
      "10000 0.6930982\n",
      "\n",
      "Hypothesis:  [[0.503147  ]\n",
      " [0.50198627]\n",
      " [0.4982264 ]\n",
      " [0.49694133]] \n",
      "Correct:  [[1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]] \n",
      "Accuracy:  tensor(0.5000)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(777)  # for reproducibility\n",
    "\n",
    "x_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.float32)\n",
    "y_data = np.array([[0], [1], [1], [0]], dtype=np.float32)\n",
    "\n",
    "X = Variable(torch.from_numpy(x_data))\n",
    "Y = Variable(torch.from_numpy(y_data))\n",
    "\n",
    "linear1 = torch.nn.Linear(2, 2, bias=True)\n",
    "linear2 = torch.nn.Linear(2, 1, bias=True)\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "model = torch.nn.Sequential(linear1, sigmoid, linear2, sigmoid)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "for step in range(10001):\n",
    "    optimizer.zero_grad()\n",
    "    hypothesis = model(X)\n",
    "    # cost/loss function\n",
    "    cost = -(Y * torch.log(hypothesis) + (1 - Y)\n",
    "             * torch.log(1 - hypothesis)).mean()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if step % 100 == 0:\n",
    "        print(step, cost.data.numpy())\n",
    "\n",
    "# Accuracy computation\n",
    "# True if hypothesis>0.5 else False\n",
    "predicted = (model(X).data > 0.5).float()\n",
    "accuracy = (predicted == Y.data).float().mean()\n",
    "print(\"\\nHypothesis: \", hypothesis.data.numpy(), \"\\nCorrect: \", predicted.numpy(), \"\\nAccuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backpropagation\n",
    "\n",
    "data_file = open(\"mnist_train.csv\", \"r\")\n",
    "training_data = data_file.readlines() #파일 내용을 한줄씩 불러와서 문자열 리스트로 반환\n",
    "data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_file = open(\"mnist_test.csv\", \"r\")\n",
    "test_data = test_data_file.readlines()\n",
    "test_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "t = np.asfarray(training_data[0].split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = t[1:].reshape(28,28) #일렬로 늘어진 784개 픽셀정보를 28x28 행렬로 바꿈\n",
    "\n",
    "plt.imshow(n, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepNeuralNetwork:\n",
    "    def __init__(self, input_layers, hidden_layers, output_layers):\n",
    "        self.inputs = input_layers\n",
    "        self.hiddens = hidden_layers\n",
    "        self.outputs = output_layers\n",
    "        self.test_data = None\n",
    "\n",
    "    # feed-forward를 진행한다.\n",
    "    def predict(self, x):\n",
    "        pass\n",
    "\n",
    "    # training_data로 학습을 진행한다.\n",
    "    def train(self, training_data, lr=0.01, epoch=1):\n",
    "        pass\n",
    "\n",
    "    # 현재 신경망의 정확도를 출력한다.\n",
    "    def print_accuracy(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = DeepNeuralNetwork(input_layers=3, hidden_layers=2, output_layers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(self, x):\n",
    "    return 1.0/(1.0 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature scaling\n",
    "def normalize(self, x):\n",
    "    return (x / 255.0) * 0.99 + 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.predict(training_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(self, x):\n",
    "    # 문자열을 float array로 바꾸는 과정\n",
    "    data = self.normalize(np.asfarray(x.split(\",\")))\n",
    "\n",
    "    # 0번은 라벨이기 때문에 날렸다.\n",
    "    data = data[1:]\n",
    "\n",
    "    layer_1 = self.sigmoid(np.dot(data, self.wih))\n",
    "    output = self.sigmoid(np.dot(layer_1, self.who))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_accuracy(self):\n",
    "    matched = 0\n",
    "\n",
    "    for x in self.test_data:\n",
    "        label = int(x[0])\n",
    "        predicted = np.argmax(self.predict(x))\n",
    "        if label == predicted :\n",
    "            matched = matched + 1\n",
    "\n",
    "    print(\"현재 신경망의 정확도 : {0}%\".format(matched/len(self.test_data)))\n",
    "# 라벨과 피드포워딩 결과가 같으면 matched 변수를 1씩 더하고, 전체 학습데이터 수로 나눠서 퍼센트 구함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepNeuralNetwork:\n",
    "    def __init__(self, input_layers, hidden_layers, output_layers):\n",
    "        inputs = input_layers\n",
    "        hiddens = hidden_layers\n",
    "        outputs = output_layers\n",
    "        test_data = None\n",
    "\n",
    "        self.w_ih = np.random.randn(inputs, hiddens) / np.sqrt(inputs/2)\n",
    "        self.w_ho = np.random.randn(hiddens, outputs) / np.sqrt(hiddens/2)\n",
    "\n",
    "    # feed-forward를 진행한다.\n",
    "    def predict(self, x):\n",
    "        # 문자열을 float array로 바꾸는 과정\n",
    "        data = self.normalize(np.asfarray(x.split(',')))\n",
    "\n",
    "        # 0번은 라벨이기 때문에 날렸다.\n",
    "        data = data[1:]\n",
    "\n",
    "        layer_1 = self.sigmoid(np.dot(data, self.wih))\n",
    "        output = self.sigmoid(np.dot(sigmoid_h, self.who))\n",
    "        return output\n",
    "\n",
    "    # training_data로 학습을 진행한다.\n",
    "    def train(self, training_data, lr=0.01, epoch=1):\n",
    "        pass\n",
    "\n",
    "    # 현재 신경망의 정확도를 출력한다.\n",
    "    def print_accuracy(self):\n",
    "        matched = 0\n",
    "\n",
    "        for x in self.test_data:\n",
    "            label = int(x[0])\n",
    "            predicted = np.argmax(predict(x))\n",
    "            if label == predicted :\n",
    "                matched = matched + 1\n",
    "        print('현재 신경망의 정확도 : {0}%'.format(matched/count(self.test_data)))\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1.0/(1.0 + np.exp(-x))\n",
    "\n",
    "    def normalize(self, x):\n",
    "        return (x / 255.0) * 0.99 + 0.01\n",
    "\n",
    "network = DeepNeuralNetwork(input_layers=784, hidden_layers=100, output_layers=10)\n",
    "network.test_data = test_data\n",
    "network.train(training_data, lr=0.01, epoch=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(self, training_data, lr=0.01, epoch=1):\n",
    "    for ech in range(0, epoch):\n",
    "        for i, x in enumerate(trainig_data):\n",
    "            target = np.array(np.zeros(self.outputs) + 0.01, ndmin=2)\n",
    "            target[0][int(x[0])] = 0.99\n",
    "            x = self.normalize(np.asfarray(x.split(\",\")))\n",
    "\n",
    "            # feed forward\n",
    "            l1 = self.sigmoid(np.dot(x[1:], self.wih))\n",
    "            l2 = self.sigmoid(np.dot(l1, self.who))\n",
    "\n",
    "            # back propagation alogrithm.\n",
    "            l2_e = (target - l2) * (l2 * (1 - l2))\n",
    "            l1_e = l2_e.dot(self.who.T) * (l1 * (1 - l1))\n",
    "\n",
    "            # update\n",
    "            self.who = self.who + lr * l2_e.T.dot(np.array(l1, ndmin=2)).T\n",
    "            self.wih = self.wih + lr * l1_e.T.dot(np.array(data[1:], ndmin=2)).T\n",
    "\n",
    "            if i % 2000 == 0 :\n",
    "                self.print_accuracy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = DeepNeuralNetwork(784,100,10)\n",
    "network.test_data = test_data\n",
    "network.train(training_data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
